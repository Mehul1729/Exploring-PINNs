{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10549039,"sourceType":"datasetVersion","datasetId":6527021}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Generation:","metadata":{}},{"cell_type":"code","source":"# CRAPPY code for  DATA GENERATION: ------------------------\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft2, ifft2, fftfreq\n\n# Simulation Parameters\nLx, Ly = 2.0, 2.0       # Domain size\nNx, Ny = 128, 128       # Grid resolution\ndx, dy = Lx / Nx, Ly / Ny\nx = np.linspace(-Lx / 2, Lx / 2, Nx)\ny = np.linspace(-Ly / 2, Ly / 2, Ny)\nX, Y = np.meshgrid(x, y)\n\ndt = 0.01               # Time step\nnu = 0.01               # Viscosity\nT = 2.0                 # Total simulation time\ntimesteps = int(T / dt)\n\n# Initial Conditions: Two Counter-Rotating Vortices\nsigma = 0.1\nGamma = 5.0  # magnitude of vorticity\nx1, y1 = -0.5, 0.0  # First vortex center\nx2, y2 = 0.5, 0.0   # Second vortex center\n\nomega = Gamma * (np.exp(-((X - x1)**2 + (Y - y1)**2) / sigma**2) - \n                 np.exp(-((X - x2)**2 + (Y - y2)**2) / sigma**2))      # omega is the vorticity\n\n# Helper functions for pseudospectral solver\ndef laplacian(f, kx, ky):\n    return -(kx**2 + ky**2) * f\n\ndef velocity(omega_hat, kx, ky):\n    u_hat = 1j * ky * omega_hat / (kx**2 + ky**2 + 1e-6)  # Avoid division by zero\n    v_hat = -1j * kx * omega_hat / (kx**2 + ky**2 + 1e-6)\n    return np.real(ifft2(u_hat)), np.real(ifft2(v_hat))\n\n# FFT-related arrays\nkx = 2 * np.pi * fftfreq(Nx, dx)\nky = 2 * np.pi * fftfreq(Ny, dy)\nkx, ky = np.meshgrid(kx, ky)\n\n# Time-stepping loop\ndata = []\nomega_hat = fft2(omega)\nfor t in range(timesteps):\n    # Calculate velocity from vorticity\n    u, v = velocity(omega_hat, kx, ky)\n\n    # Advect vorticity using pseudospectral method\n    omega_x = np.real(ifft2(1j * kx * omega_hat))\n    omega_y = np.real(ifft2(1j * ky * omega_hat))\n    adv_omega = u * omega_x + v * omega_y\n\n    # Diffusion\n    diffusion = laplacian(omega_hat, kx, ky)\n\n    # Time update\n    omega_hat -= dt * fft2(adv_omega - nu * diffusion)\n\n    # Save data\n    if t % 5 == 0:  # Save every 5 steps\n        omega = np.real(ifft2(omega_hat))\n        data.append((t * dt, u, v, omega))\n\n# Save the data to a file\n\n# Create separate lists for saving each variable\ntimes = []\nu_list = []\nv_list = []\nomega_list = []\n\n# Save data\nfor t, u, v, omega in data:\n    times.append(t)\n    u_list.append(u)\n    v_list.append(v)\n    omega_list.append(omega)\n\n# Convert to numpy arrays\ntimes = np.array(times)\nu_list = np.array(u_list)\nv_list = np.array(v_list)\nomega_list = np.array(omega_list)\n\n\"\"\"\n# Save separately\nnp.save(\"vortex_times.npy\", times)\nnp.save(\"vortex_u.npy\", u_list)\nnp.save(\"vortex_v.npy\", v_list)\nnp.save(\"vortex_omega.npy\", omega_list)\n\n\"\"\"\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nomega_list = np.load(\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_omega.npy\")\nu_list = np.load(\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_u.npy\")\nv_list = np.load(\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_v.npy\")\ntimes = np.load(\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_times.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:58:18.682996Z","iopub.execute_input":"2025-01-22T12:58:18.683351Z","iopub.status.idle":"2025-01-22T12:58:19.091312Z","shell.execute_reply.started":"2025-01-22T12:58:18.683308Z","shell.execute_reply":"2025-01-22T12:58:19.089727Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-79a3af237d5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0momega_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_omega.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mu_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_u.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_v.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_times.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_omega.npy'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:\\\\Users\\\\mehul\\\\MyLab\\\\Folderss\\\\PINN\\\\datasets\\\\Vortex2D\\\\separated files\\\\vortex_omega.npy'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"## FOR KAGGLE ONLY: \n# -----------------------MATLAB DATA ---------------------------------------- \nimport numpy as np\nomega_list = np.load(\"/kaggle/input/vortex/vortex_omega.npy\")\nu_list = np.load(\"/kaggle/input/vortex/vortex_u.npy\")\nv_list = np.load(\"/kaggle/input/vortex/vortex_v.npy\")\ntimes = np.load(\"/kaggle/input/vortex/vortex_times.npy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T13:17:09.607307Z","iopub.execute_input":"2025-01-22T13:17:09.607605Z","iopub.status.idle":"2025-01-22T13:17:09.704262Z","shell.execute_reply.started":"2025-01-22T13:17:09.607580Z","shell.execute_reply":"2025-01-22T13:17:09.703026Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# Claude code:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft2, ifft2, fftfreq\n\n# Simulation Parameters\nLx, Ly = 2.0, 2.0       # Domain size\nNx, Ny = 128, 128       # Grid resolution\ndx, dy = Lx / Nx, Ly / Ny\nx = np.linspace(-Lx / 2, Lx / 2, Nx)\ny = np.linspace(-Ly / 2, Ly / 2, Ny)\nX, Y = np.meshgrid(x, y)\ndt = 0.05               # Time step\nnu = 0.01               # Viscosity\nT = 2.0                 # Total simulation time\ntimesteps = int(T / dt)\n\n# Initial Conditions: Two Counter-Rotating Vortices\nsigma = 0.1\nGamma = 5.0  # magnitude of vorticity\nx1, y1 = -0.5, 0.0  # First vortex center\nx2, y2 = 0.5, 0.0   # Second vortex center\nomega = Gamma * (np.exp(-((X - x1)**2 + (Y - y1)**2) / sigma**2) - \n                np.exp(-((X - x2)**2 + (Y - y2)**2) / sigma**2))\n\n# Helper functions for pseudospectral solver\ndef laplacian(f, kx, ky):\n    return -(kx**2 + ky**2) * f\n\ndef velocity(omega_hat, kx, ky):\n    u_hat = 1j * ky * omega_hat / (kx**2 + ky**2 + 1e-6)\n    v_hat = -1j * kx * omega_hat / (kx**2 + ky**2 + 1e-6)\n    return np.real(ifft2(u_hat)), np.real(ifft2(v_hat))\n\n# FFT-related arrays\nkx = 2 * np.pi * fftfreq(Nx, dx)\nky = 2 * np.pi * fftfreq(Ny, dy)\nkx, ky = np.meshgrid(kx, ky)\n\n# Time-stepping loop\nomega_hat = fft2(omega)\ntimes = []\nomega_values = []\n\n# Run simulation\nfor t in range(timesteps):\n    # Calculate velocity from vorticity\n    u, v = velocity(omega_hat, kx, ky)\n    \n    # Advect vorticity using pseudospectral method\n    omega_x = np.real(ifft2(1j * kx * omega_hat))\n    omega_y = np.real(ifft2(1j * ky * omega_hat))\n    adv_omega = u * omega_x + v * omega_y\n    \n    # Diffusion\n    diffusion = laplacian(omega_hat, kx, ky)\n    \n    # Time update\n    omega_hat -= dt * fft2(adv_omega - nu * diffusion)\n    \n    # Save time and omega\n    if t % 1 == 0:\n        times.append(t * dt)\n        current_omega = np.real(ifft2(omega_hat))\n        omega_values.append(current_omega)\n\n# Get final state for u and v\nu_final, v_final = velocity(omega_hat, kx, ky)\n\n# Extract 1D arrays\nu_final = u_final[64, :]        # Take middle row for u (128 points)\nv_final = v_final[:, 64]        # Take middle column for v (128 points)\n\n# Process omega values\nomega_values = np.array(omega_values[:40])  # Keep first 40 timesteps\nomega_final = omega_values.reshape(-1)      # Flatten to 1D array (128*128*40 points)\n\ntimes = np.array(times)[:40]     # Keep only first 40 time points\n\n# Save arrays to file\nnp.savez('vortex_data_1d.npz', \n         times=times,           # 40 time values\n         u=u_final,            # 128 values (spatial points only)\n         v=v_final,            # 128 values (spatial points only)\n         omega=omega_final)    # 128*128*40 values (all unique combinations)\n\n# Print shapes to verify\nprint(\"Times shape:\", times.shape)        # Should be (40,)\nprint(\"u_final shape:\", u_final.shape)    # Should be (128,)\nprint(\"v_final shape:\", v_final.shape)    # Should be (128,)\nprint(\"omega_final shape:\", omega_final.shape)  # Should be (655360,) = 128*128*40","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:27:20.600582Z","iopub.execute_input":"2025-01-31T19:27:20.600896Z","iopub.status.idle":"2025-01-31T19:27:21.276668Z","shell.execute_reply.started":"2025-01-31T19:27:20.600864Z","shell.execute_reply":"2025-01-31T19:27:21.274702Z"}},"outputs":[{"name":"stdout","text":"Times shape: (40,)\nu_final shape: (128,)\nv_final shape: (128,)\nomega_final shape: (655360,)\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-136fb27b32f3>:54: RuntimeWarning: overflow encountered in multiply\n  adv_omega = u * omega_x + v * omega_y\n<ipython-input-1-136fb27b32f3>:54: RuntimeWarning: invalid value encountered in add\n  adv_omega = u * omega_x + v * omega_y\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"u_final.size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:27:37.418314Z","iopub.execute_input":"2025-01-31T19:27:37.418667Z","iopub.status.idle":"2025-01-31T19:27:37.424841Z","shell.execute_reply.started":"2025-01-31T19:27:37.418640Z","shell.execute_reply":"2025-01-31T19:27:37.423843Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"128"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"chunk_size = 2000\nnum_points = len(u_final)\n\nN_train = 2000  # Number of collocation points\nX_star_list = []\nO_star_list = []\n\n# Reshape omega_final back to its original 3D shape\nNx, Ny, timesteps = 128, 128, 40  # Original dimensions\nomega_final_reshaped = omega_final.reshape(Nx, Ny, timesteps)\n\n# Chunked data processing\ndef process_in_chunks(u_final, v_final, times, omega_final_reshaped, chunk_size):\n    num_points = u_final.size\n    num_chunks = int(np.ceil(num_points / chunk_size))\n    k = 0\n    for i in range(num_chunks):\n        k += 1\n        # Determine the start and end indices for the chunk\n        start_idx = i * chunk_size\n        end_idx = min(start_idx + chunk_size, num_points)\n\n        # Convert indices back to grid coordinates\n        t_idx = np.arange(timesteps)  # Time indices\n        x_idx = np.arange(Nx)        # X-space indices\n        y_idx = np.arange(Ny)        # Y-space indices\n\n        # Extract the chunk\n        t_chunk = times[t_idx[start_idx:end_idx]]\n        u_chunk = u_final[x_idx[start_idx:end_idx]]\n        v_chunk = v_final[y_idx[start_idx:end_idx]]\n\n        # Create the meshgrid for the chunk\n        T_chunk, U_chunk, V_chunk = np.meshgrid(t_chunk, u_chunk, v_chunk, indexing='ij')\n        X_star_chunk = np.hstack((U_chunk.flatten()[:, None], V_chunk.flatten()[:, None], T_chunk.flatten()[:, None]))\n\n        # Get the corresponding solution values\n        o_star_chunk = omega_final_reshaped[:, :, t_idx[start_idx:end_idx]].flatten()[:, None]\n\n        # Yield the chunk\n        yield X_star_chunk, o_star_chunk\n\n# Process the data in chunks\nfor X_star_chunk, o_star_chunk in process_in_chunks(u_final, v_final, times, omega_final_reshaped, chunk_size):\n    X_star_list.append(X_star_chunk)\n    O_star_list.append(o_star_chunk)\n\n# Combine all chunks into a single array\nX_star_list = np.vstack(X_star_list)\nO_star_list = np.vstack(O_star_list)\n\n# Verify the result\nprint(\"Final X_star shape:\", X_star_list.shape)\nprint(\"Final O_star shape:\", O_star_list.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:27:39.516120Z","iopub.execute_input":"2025-01-31T19:27:39.516522Z","iopub.status.idle":"2025-01-31T19:27:39.572848Z","shell.execute_reply.started":"2025-01-31T19:27:39.516492Z","shell.execute_reply":"2025-01-31T19:27:39.572036Z"}},"outputs":[{"name":"stdout","text":"Final X_star shape: (655360, 3)\nFinal O_star shape: (655360, 1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Training Main:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:27:42.833655Z","iopub.execute_input":"2025-01-31T19:27:42.833977Z","iopub.status.idle":"2025-01-31T19:27:56.779835Z","shell.execute_reply.started":"2025-01-31T19:27:42.833953Z","shell.execute_reply":"2025-01-31T19:27:56.778803Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport os\n\n# Set DeepXDE backend to PyTorch\nos.environ[\"DDE_BACKEND\"] = \"pytorch\"\n\n# Import DeepXDE after setting the backend\nimport deepxde as dde","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:27:56.780961Z","iopub.execute_input":"2025-01-31T19:27:56.781513Z","iopub.status.idle":"2025-01-31T19:28:00.698604Z","shell.execute_reply.started":"2025-01-31T19:27:56.781486Z","shell.execute_reply":"2025-01-31T19:28:00.697186Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-493027475f6a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import DeepXDE after setting the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdeepxde\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepxde'"],"ename":"ModuleNotFoundError","evalue":"No module named 'deepxde'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"N_train = 2000\nidx = np.random.choice(X_star_list.shape[0], N_train, replace=False)  # randomly sampling collocation pts from trainng data\nX_train = X_star_list[idx, :]\nomega_train = O_star_list[idx, :]\n\n# converting to tensors\nomega_train = tf.convert_to_tensor(O_star_list, dtype=tf.double)\nX_train = tf.convert_to_tensor(X_star_list, dtype=tf.double)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:30:04.846640Z","iopub.execute_input":"2025-01-31T19:30:04.847010Z","iopub.status.idle":"2025-01-31T19:30:04.928037Z","shell.execute_reply.started":"2025-01-31T19:30:04.846984Z","shell.execute_reply":"2025-01-31T19:30:04.927213Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"### DOESN'T WORK AS OF NOW ----------------------------------- \n\n\nclass PhysicsInformedNN:\n    def __init__(self, X_train, omega_train, layers):\n        \"\"\"\n        Initialize the Physics-Informed Neural Network (PINN).\n\n        Parameters:\n        - X_train: Input training data (spatial and temporal coordinates)\n        - omega_train: Corresponding training labels (vorticity values)\n        - layers: List defining the architecture of the neural network\n        \"\"\"\n        self.X_train = tf.convert_to_tensor(X_train, dtype=tf.double)\n        self.omega_train = tf.convert_to_tensor(omega_train, dtype=tf.double)\n        self.layers = layers\n\n        # Initialize neural network parameters (weights and biases)\n        self.weights, self.biases = self.initialize_NN(layers)\n\n        # Set up the optimizer\n        self.optimizer = tf.keras.optimizers.Adam()\n\n    def initialize_NN(self, layers):\n        \"\"\"\n        Initialize the neural network weights and biases using Xavier initialization.\n        \"\"\"\n        weights = []\n        biases = []\n        for l in range(len(layers) - 1):\n            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.double))\n            weights.append(W)\n            biases.append(b)\n        return weights, biases\n\n    def xavier_init(self, size):\n        \"\"\"\n        Generate weights using Xavier initialization for proper scaling.\n        \"\"\"\n        in_dim = size[0]\n        out_dim = size[1]\n        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n        return tf.Variable(tf.random.normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.double), dtype=tf.double)\n\n    def forward_pass(self, X):\n        \"\"\"\n        Define the forward pass through the neural network.\n        \"\"\"\n        A = X\n        for l in range(len(self.weights) - 1):\n            W = self.weights[l]\n            b = self.biases[l]\n            A = tf.tanh(tf.add(tf.matmul(A, W), b))  # Activation function: tanh\n        W = self.weights[-1]\n        b = self.biases[-1]\n        output = tf.add(tf.matmul(A, W), b)  # Linear output layer\n        return output\n    \n    \n    def physics_loss(self, X):\n        \"\"\"\n        Compute the physics loss using the vorticity transport equation.\n        \"\"\"\n        with tf.GradientTape(persistent=True) as tape:\n            tape.watch(X)\n            omega = self.forward_pass(X)\n\n            omega_t = tape.gradient(omega, X)[:, 2:3]  # ∂ω/∂t\n            omega_x = tape.gradient(omega, X)[:, 0:1]  # ∂ω/∂x\n            omega_y = tape.gradient(omega, X)[:, 1:2]  # ∂ω/∂y\n\n        # Compute second derivatives\n        omega_xx = tape.gradient(omega_x, X)[:, 0:1]  # ∂²ω/∂x²\n        omega_yy = tape.gradient(omega_y, X)[:, 1:2]  # ∂²ω/∂y²\n\n        del tape  # Free the resources of the gradient tape\n\n        u = X[:, 3:4]  # u velocity (provided as input)\n        v = X[:, 4:5]  # v velocity (provided as input)\n\n        # Compute residual of the vorticity transport equation\n        residual = omega_t + u * omega_x + v * omega_y - self.nu * (omega_xx + omega_yy)\n        return tf.reduce_mean(tf.square(residual))\n    \n\n    def compute_loss(self,X):  # fucntion to calculate the total loss\n    \n        loss = self.physics_loss(self.X_train)\n        return loss\n    \n    def train(self, nIter):\n        # Purpose: Train the network by minimizing the total loss using gradient descent.\n        for it in range(nIter): # iterating for epochs = nIter\n            with tf.GradientTape() as tape: # to calculate gradients for physics loss\n                loss = self.compute_loss(X_train)\n            gradients = tape.gradient(loss, self.weights + self.biases) # gradients for final optimization of the total loss\n            self.optimizer.apply_gradients(zip(gradients, self.weights + self.biases)) # passing the params to be used to optimize as a single listz\n\n            if it % 100 == 0:\n                print(f\"Iteration {it}, Loss: {loss.numpy()}\")\n        \n        \n    def predict(self, X_star_list):\n        # Purpose: Use the trained network to predict solutions for new data points.\n        o_pred = self.forward_pass(X_star_list)\n        return o_pred.numpy()\n    \nlayers = [2, 20, 20, 20, 1]  # Input layer, hidden layers, and output layer\nmodel = PhysicsInformedNN(X_train, omega_train, layers)\nmodel.train(4000)  # Train for 4,000 iterations\n\no_pred = model.predict(X_star_list)\n\no_pred = o_pred.reshape(Exact.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:28:00.700049Z","iopub.status.idle":"2025-01-31T19:28:00.700356Z","shell.execute_reply":"2025-01-31T19:28:00.700221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# WORKING BUT BUGGY: --------------------------------- \n\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nclass PhysicsInformedNN:\n    def __init__(self, X_train, omega_train, layers, nu):\n        \"\"\"\n        Initialize the Physics-Informed Neural Network (PINN).\n\n        Parameters:\n        - X_train: Input training data (spatial and temporal coordinates)\n        - omega_train: Corresponding training labels (vorticity values)\n        - layers: List defining the architecture of the neural network\n        - nu: Viscosity (parameter in the vorticity transport equation)\n        \"\"\"\n        self.X_train = tf.convert_to_tensor(X_train, dtype=tf.double)\n        self.omega_train = tf.convert_to_tensor(omega_train, dtype=tf.double)\n        self.layers = layers\n        self.nu = nu\n\n        # Initialize neural network parameters (weights and biases)\n        self.weights, self.biases = self.initialize_NN(layers)\n\n        # Set up the optimizer\n        self.optimizer = tf.keras.optimizers.Adam()\n\n    def initialize_NN(self, layers):\n        \"\"\"\n        Initialize the neural network weights and biases using Xavier initialization.\n        \"\"\"\n        weights = []\n        biases = []\n        for l in range(len(layers) - 1):\n            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.double))\n            weights.append(W)\n            biases.append(b)\n        return weights, biases\n\n    def xavier_init(self, size):\n        \"\"\"\n        Generate weights using Xavier initialization for proper scaling.\n        \"\"\"\n        in_dim = size[0]\n        out_dim = size[1]\n        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n        return tf.Variable(tf.random.normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.double), dtype=tf.double)\n\n    def forward_pass(self, X):\n        \"\"\"\n        Define the forward pass through the neural network.\n        \"\"\"\n        A = X\n        for l in range(len(self.weights) - 1):\n            W = self.weights[l]\n            b = self.biases[l]\n            A = tf.tanh(tf.add(tf.matmul(A, W), b))  # Activation function: tanh\n        W = self.weights[-1]\n        b = self.biases[-1]\n        output = tf.add(tf.matmul(A, W), b)  # Linear output layer\n        return output\n\n    def physics_loss(self, X):\n        \"\"\"\n        Compute the physics loss using the vorticity transport equation.\n        \"\"\"\n        with tf.GradientTape(persistent=True) as tape:\n            tape.watch(X)\n            omega = self.forward_pass(X)\n\n            omega_t = tape.gradient(omega, X)[:, 2:3]  # ∂ω/∂t\n            omega_x = tape.gradient(omega, X)[:, 0:1]  # ∂ω/∂x\n            omega_y = tape.gradient(omega, X)[:, 1:2]  # ∂ω/∂y\n\n        # Compute second derivatives\n        omega_xx = tape.gradient(omega_x, X)[:, 0:1]  # ∂²ω/∂x²\n        omega_yy = tape.gradient(omega_y, X)[:, 1:2]  # ∂²ω/∂y²\n\n        del tape  # Free the resources of the gradient tape\n\n        u = X[:, 3:4]  # u velocity (provided as input)\n        v = X[:, 4:5]  # v velocity (provided as input)\n\n        # Compute residual of the vorticity transport equation\n        residual = omega_t + u * omega_x + v * omega_y - self.nu * (omega_xx + omega_yy)\n        return tf.reduce_mean(tf.square(residual))\n\n    def compute_loss(self):\n        \"\"\"\n        Calculate the total loss (physics loss only in this case).\n        \"\"\"\n        return self.physics_loss(self.X_train)\n\n    def train(self, nIter):\n        \"\"\"\n        Train the network by minimizing the total loss using gradient descent.\n        \"\"\"\n        for it in range(nIter):  # Iterating for epochs = nIter\n            with tf.GradientTape() as tape:  # To calculate gradients for physics loss\n                loss = self.compute_loss()\n            gradients = tape.gradient(loss, self.weights + self.biases)  # Gradients for optimization\n            self.optimizer.apply_gradients(zip(gradients, self.weights + self.biases))  # Optimize weights and biases\n\n            if it % 100 == 0:\n                print(f\"Iteration {it}, Loss: {loss.numpy()}\")\n\n    def predict(self, X_star):\n        \"\"\"\n        Use the trained network to predict solutions for new data points.\n        \"\"\"\n        X_star_tensor = tf.convert_to_tensor(X_star, dtype=tf.double)\n        omega_pred = self.forward_pass(X_star_tensor)\n        return omega_pred.numpy()\n\n# Parameters\nlayers = [3, 50, 50, 50, 1]  # Input layer (x, y, t), hidden layers, and output layer (omega)\nnu = 0.01  # Viscosity\n\n# Define the spatial-temporal grid\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 1, 100)\nt = np.linspace(0, 1, 100)\nX, Y, T = np.meshgrid(x, y, t)\nX_star = np.hstack((X.flatten()[:, None], Y.flatten()[:, None], T.flatten()[:, None]))\n\n# Initialize and train the PINN\nmodel = PhysicsInformedNN(X_train, omega_train, layers, nu)\nmodel.train(4000)\n\n# Predict omega values\nomega_pred = model.predict(X_star)\nomega_pred = omega_pred.reshape(X.shape)\n\n# Generate frames for visualization\nfor i, t_val in enumerate(t):\n    plt.figure()\n    plt.contourf(X[:, :, i], Y[:, :, i], omega_pred[:, :, i], levels=50, cmap=\"jet\")\n    plt.colorbar()\n    plt.title(f\"Vorticity at t = {t_val:.2f}\")\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    plt.savefig(f\"frame_{i:03d}.png\")\n    plt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T19:30:14.742944Z","iopub.execute_input":"2025-01-31T19:30:14.743279Z","iopub.status.idle":"2025-01-31T19:32:14.883682Z","shell.execute_reply.started":"2025-01-31T19:30:14.743253Z","shell.execute_reply":"2025-01-31T19:32:14.882392Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:678: UserWarning: Gradients do not exist for variables ['Variable:0'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: nan\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f60e2f9f07da>\u001b[0m in \u001b[0;36m<cell line: 131>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# Initialize and train the PINN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysicsInformedNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Predict omega values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-f60e2f9f07da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nIter)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# To calculate gradients for physics loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradients for optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Optimize weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m def _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs,\n\u001b[0m\u001b[1;32m    119\u001b[0m                        out_grads, skip_input_indices, forward_pass_name_scope):\n\u001b[1;32m    120\u001b[0m   \"\"\"Calls the gradient function of the op.\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}